
DONE:
-----------------------------------------
generate 1st layer
train 1st layer
test 1st layer 
train 2nd layer k-means
[all done on CIFAR]



TO DO:
-----------------------------------------
this is a list of things to do:

1- continue the SpatialSAD module integration.

2 - I found out problems with learning a 2nd layer. See figure below 2nd layer filters. They are dots. It means that it is taking filters from the 1st layer and pushing them on the 2nd layer as relevant. 
Also LPP2 pooling works well, because of reasons mentioned above
We need:
- train larger set of filters on 2nd layer
- then filter out the filters that have only dot-like features, and keep the ones with more sophisticated content
we need a program to do this
- try again on SVHN or CIFAR, first using the new 2nd layer filters and seeing if we get good results.
Also feed to classifier BOTH 1st layer and 2nd layer filters, to improve recognition rate. 

3-  figure out how to save a net in torch without taking GB?



--k-means in unsup generates some nan filters: due to divide by 0 when templates are not used
NOT AN ISSUE, just need more initial STD

normalize and zero mean data after each layer!
DONE if needed

test on a dataset 2 layer net
NO GOOD RESULTS YET

SpatialSAD: how to deal with input kernels, input have 3 color spaces: 3 x 2-dimensions
but then in 2nd layer we have input with many dimensions and filters are 1 x 2 dimensions:
meaning that at least now filters are shared for all input dimensions
how to connect 1st and second layer? conned table: pick M subset of inputs and compute SpatialSAD on that
or just use all of them if you have time for computation
What I would like is to learn filter, kernels that are independent of color planes
so filters in each layer are always N x 2-dimensions


CIFAR too small for 2 or more layers: switch to other dataset
switch to: SVHN dataset:
http://ufldl.stanford.edu/housenumbers/
or spanish dataset on our server (even better for final use)


STUDENT TASK:
- “Filter” k-means filters so that they are different: group them together and remove copies!!!
- group them as in Adam Coates paper NIPS 2011

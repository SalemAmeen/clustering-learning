\relax 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\citation{lecun-98,hadsell-chopra-lecun-06,gregor-nips-11,Riesenhuber1999,Serre2007,Serre2010}
\citation{jarrett-iccv-09,lecun-iscas-10,boureau-icml-10}
\citation{Karpathy2011,Torralba2011,hou2012meta}
\citation{Olshausen1996,Hyvarinen2000,Hinton2006,Vincent2008,Coates2011}
\citation{Coates2011}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\citation{Collobert2011}
\citation{Krizhevsky2009}
\citation{Netzer2011}
\citation{MartinFTM01}
\citation{Kalal2011}
\citation{jarrett-iccv-09}
\citation{Wandell95}
\@writefile{toc}{\contentsline {section}{\numberline {2}Methods}{2}{section.2}}
\newlabel{sec-methods}{{2}{2}{Methods\relax }{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Input data}{2}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Network architecture}{2}{subsection.2.2}}
\newlabel{sec-net-arch}{{2.2}{2}{Network architecture\relax }{subsection.2.2}{}}
\citation{sermanet-icpr-12,boureau-icml-10,lecun-iscas-10}
\citation{lecun-98,Hinton2006,Krizhevsky2009,jarrett-iccv-09}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Architecture of one layer of the clustering learning (CL) network. Filters were applied with a sum-abs-diff operations, followed by contrastive normalization, L-2 pooling of features, nonlinearity tanh, and subtractive normalization.\relax }}{3}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig-CL-layer}{{1}{3}{Architecture of one layer of the clustering learning (CL) network. Filters were applied with a sum-abs-diff operations, followed by contrastive normalization, L-2 pooling of features, nonlinearity tanh, and subtractive normalization.\relax \relax }{figure.caption.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Learning}{3}{subsection.2.3}}
\citation{lecun-iscas-10}
\citation{Kalal2011}
\citation{Farabet2012}
\citation{Farabet2012}
\citation{MartinFTM01}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Filters obtained with clustering learning on the 1st and 2nd layer. The filters obtained on the 1st layer are quite similar to elongated Gabor patches, and what can be obtained with more complex and numerically involved unsupervised techniques. Filter training with CL was obtained in \nobreakspace  {}10 min time on a modern laptop.\relax }}{4}{figure.caption.2}}
\newlabel{fig-filters}{{2}{4}{Filters obtained with clustering learning on the 1st and 2nd layer. The filters obtained on the 1st layer are quite similar to elongated Gabor patches, and what can be obtained with more complex and numerically involved unsupervised techniques. Filter training with CL was obtained in ~10 min time on a modern laptop.\relax \relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Real-time network}{4}{section.3}}
\newlabel{section-realtime}{{3}{4}{Real-time network\relax }{section.3}{}}
\citation{Coates2011,Coates2011b}
\citation{Coates2011,lecun-iscas-10}
\citation{Coates2011,Coates2011b}
\citation{Ciresan2012}
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{5}{section.4}}
\newlabel{sec-results}{{4}{5}{Results\relax }{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Static datasets}{5}{subsection.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Test set accuracy comparison for a convolutional neural network (CNN) and a clustering learning (CL) network with 1 and 2 layers on the SVHN dataset\relax }}{5}{figure.caption.3}}
\newlabel{data_svhn}{{3}{5}{Test set accuracy comparison for a convolutional neural network (CNN) and a clustering learning (CL) network with 1 and 2 layers on the SVHN dataset\relax \relax }{figure.caption.3}{}}
\citation{Kalal2011}
\citation{TLD}
\citation{Farabet2012}
\citation{Dundar2012,TLD}
\citation{Farabet2012}
\citation{Farabet2012}
\citation{Kalal2011}
\citation{Farabet2012}
\citation{Kalal2011}
\citation{Farabet2012}
\citation{Farabet2012}
\citation{Socher2012}
\citation{Coates2011b}
\citation{Krizhevsky2012}
\citation{Ciresan2012}
\citation{jarrett-iccv-09}
\citation{Coates2011b,Ciresan2012}
\citation{Socher2012}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Test set accuracy comparison for a convolutional neural network (CNN) and a clustering learning (CL) network with 1 and 2 layers on the CIFAR10 dataset\relax }}{6}{figure.caption.4}}
\newlabel{data_cifar}{{4}{6}{Test set accuracy comparison for a convolutional neural network (CNN) and a clustering learning (CL) network with 1 and 2 layers on the CIFAR10 dataset\relax \relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Dynamic datasets}{6}{subsection.4.2}}
\citation{Farabet2011}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Precision comparison between of a Clustering Learning (CL) network and a convolutional neural network (CNN)\cite  {Farabet2012} used as trackers in the TLD dataset \cite  {Kalal2011}.\relax }}{7}{table.caption.5}}
\newlabel{table1}{{1}{7}{Precision comparison between of a Clustering Learning (CL) network and a convolutional neural network (CNN)\cite {Farabet2012} used as trackers in the TLD dataset \cite {Kalal2011}.\relax \relax }{table.caption.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Comparison of execution time of state-of-the-art networks as compared to the proposed CL network.\relax }}{7}{table.caption.6}}
\newlabel{table2}{{2}{7}{Comparison of execution time of state-of-the-art networks as compared to the proposed CL network.\relax \relax }{table.caption.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Discussion}{7}{section.5}}
\citation{Sanger89,Foldiak90,Oja89,Bell97}
\bibcite{lecun-98}{1}
\bibcite{hadsell-chopra-lecun-06}{2}
\bibcite{gregor-nips-11}{3}
\bibcite{Riesenhuber1999}{4}
\bibcite{Serre2007}{5}
\bibcite{Serre2010}{6}
\bibcite{sermanet-icpr-12}{7}
\bibcite{jarrett-iccv-09}{8}
\bibcite{lecun-iscas-10}{9}
\bibcite{boureau-icml-10}{10}
\bibcite{Coates2011}{11}
\bibcite{Coates2011b}{12}
\bibcite{Ciresan2012}{13}
\bibcite{neuflow}{14}
\bibcite{Olshausen1996}{15}
\bibcite{Hyvarinen2000}{16}
\bibcite{Hinton2006}{17}
\bibcite{Vincent2008}{18}
\bibcite{Karpathy2011}{19}
\bibcite{Torralba2011}{20}
\bibcite{hou2012meta}{21}
\bibcite{Collobert2011}{22}
\bibcite{Krizhevsky2009}{23}
\bibcite{Netzer2011}{24}
\bibcite{Farabet2012}{25}
\bibcite{Netzer2011}{26}
\bibcite{Wandell95}{27}
\bibcite{Kalal2011}{28}
\bibcite{MartinFTM01}{29}
\bibcite{TLD}{30}
\bibcite{Dundar2012}{31}
\bibcite{Socher2012}{32}
\bibcite{Krizhevsky2012}{33}
\bibcite{Farabet2011}{34}
\bibcite{Sanger89}{35}
\bibcite{Foldiak90}{36}
\bibcite{Oja89}{37}
\bibcite{Bell97}{38}
